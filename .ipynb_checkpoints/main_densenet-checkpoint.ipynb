{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residential Building Classification\n",
    "This is a bare-bone version of the residential vs. non-residential building classification. We use DenseNet in this implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import params\n",
    "from densenet_efficient import DenseNetEfficient\n",
    "from solver import train, test_epoch\n",
    "from dataset import *\n",
    "\n",
    "# Load parameters\n",
    "params = vars(params)\n",
    "rbc_class_names = params['rbc_class_names']\n",
    "fmow_class_names = params['fmow_class_names']\n",
    "fmow_class_names_mini = params['fmow_class_names_mini']\n",
    "dtype = params['dtype']\n",
    "\n",
    "torch.set_num_threads(params['num_threads'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess FMOW Dataset\n",
    "Check if fMoW dataset is available. If so, process the images by cropping based on given bounding boxes. Load in traing, validation and test dataset along with ground truth labels for training and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([1, 224, 224]) <class 'torch.LongTensor'> torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "mean = 0.5\n",
    "stdv = 0.25\n",
    "train_transforms = transforms.Compose([\n",
    "    Normalize(mean=mean, std=stdv),\n",
    "    Rescale((224,224)),\n",
    "    ToTensor(),\n",
    "])\n",
    "train_set = FMOWDataset(params, transform=train_transforms)\n",
    "x,y = train_set[0]\n",
    "print(type(x), x.shape, type(y), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([1, 224, 224]) <class 'torch.LongTensor'> torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "mean = 0.5\n",
    "stdv = 0.25\n",
    "train_transforms = transforms.Compose([\n",
    "    Normalize(mean=mean, std=stdv),\n",
    "    Rescale((224,224)),\n",
    "    ToTensor(),\n",
    "])\n",
    "test_set = FMOWDataset_test(params, transform=train_transforms)\n",
    "x,y = test_set[0]\n",
    "print(type(x), x.shape, type(y), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = load_test(params, mean_image=None)\n",
    "# X_test = data_test['X_test']\n",
    "# y_test = data_test['y_test']\n",
    "# X_test_tensor = torch.from_numpy(X_test)\n",
    "# y_test_tensor = torch.from_numpy(y_test)\n",
    "# test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "# loader_test = DataLoader(test_data, batch_size=params['batch_size'], sampler=RandomSampler(X_test.shape[0]))\n",
    "# print(X_test.shape, X_test.dtype)\n",
    "# print(y_test.shape, y_test.dtype)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a small batch of data\n",
    "Plot a small batch of training images to get a sense of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5349aaf160e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rbc_class_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample a minibatch and show the images and captions\n",
    "size = 5\n",
    "indices = np.random.choice(len(test_set), size, replace=False)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    image, label = test_set[idx]\n",
    "    plt.subplot(1, size, i + 1)\n",
    "    plt.title(params['rbc_class_names'][label[0]])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image[0,:,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "Load in pre-trained DenseNet. Configure training parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive two-layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feng/anaconda3/envs/rbc_env/lib/python3.6/site-packages/torch/nn/modules/container.py:13: UserWarning: nn.Container is deprecated. All of it's functionality is now implemented in nn.Module. Subclass that instead.\n",
      "  warnings.warn(\"nn.Container is deprecated. All of it's functionality \"\n"
     ]
    }
   ],
   "source": [
    "model = DenseNetEfficient(\n",
    "        growth_rate=32, \n",
    "        block_config=(6, 12, 24, 16), \n",
    "        compression=0.5,\n",
    "        num_init_features=64, \n",
    "        bn_size=4, \n",
    "        drop_rate=0,\n",
    "        num_classes=20, \n",
    "        small_inputs=False)\n",
    "# Move model to GPU\n",
    "model = model.cuda()\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an existing model\n",
    "model.load_state_dict(torch.load('/home/feng/ext2/feng/workspace/residential_building_challenge/output/model.dat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Train the model one epoch at a time. Keep the verbose option on to monitor the loss during training. \n",
    "Save training and validation accuracy history for visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[ 45   7   1   0   2   5   4   0   0   0   1   2   2   4   0   1   2   0\n",
    "    0   0]\n",
    " [  2  34   1   0   1   6   1   4   0   2   6   2   0   6   2   0   1   8\n",
    "    0   0]\n",
    " [  1   1 101   0   2   3   4  13   0  12   1   3   3  12   5   5   2   3\n",
    "    0   0]\n",
    " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0]\n",
    " [  0   3   2   0  19   0   1   1   0   7   0   0   1   0   0   0   2   0\n",
    "    1   0]\n",
    " [  4   2   1   0   0  22   4   1   0   0   1   2   2  11   3   0   3   1\n",
    "    0   0]\n",
    " [  3   3   1   0   2   2  95   2   0   8   2   2   7   6   3   0   0   1\n",
    "    0   0]\n",
    " [  0   1   8   0   1   2   4  19   0   7   4   2   1   7   3   1   0   1\n",
    "    0   0]\n",
    " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0]\n",
    " [  1   2   9   0   3   3   3   3   0 111   1   1   3   6   2   2   7   4\n",
    "    0   0]\n",
    " [  1   0   2   0   0   1   3   8   0   3  44   5   4   9   3   0   0  14\n",
    "    0   0]\n",
    " [  3   4   6   0   0   5   9   8   0   1   3  18   6   8   3   1   0   2\n",
    "    0   0]\n",
    " [  1   4   6   0   2   2  12   5   0   7   3   0 123   4   6   1  12   3\n",
    "    0   0]\n",
    " [  2   7  10   0   0  13   9  10   0   5   6   6   3 153   3   0   6   8\n",
    "    0   0]\n",
    " [  0   3   4   0   0  12   4   5   0   4   4   8   2   9  14   0   0   3\n",
    "    0   0]\n",
    " [  0   0   5   0   1   0   1   1   0   9   0   0   0   0   0  46   2   1\n",
    "    0   0]\n",
    " [  2   0   3   0   0   1   1   0   0   4   1   3   8   5   0   0 315   2\n",
    "    0   0]\n",
    " [  0   5   1   0   0   5   3   0   0   1  12   2   1  18   4   0   2  79\n",
    "    0   0]\n",
    " [  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
    "    0   0]\n",
    " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0]]\n",
    "res detect 79 + 44 = 123\n",
    "res total 133 + 97 = 230 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-15baa745fcea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       seed=None)\n\u001b[0m",
      "\u001b[0;32m/ext2/feng/feng/workspace/residential_building_challenge/demo.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_set, test_set, save, n_epochs, valid_size, batch_size, lr, wd, momentum, seed)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         )\n\u001b[1;32m    277\u001b[0m         _, valid_loss, valid_error = test_epoch(\n",
      "\u001b[0;32m/ext2/feng/feng/workspace/residential_building_challenge/demo.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, epoch, n_epochs, print_freq)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rbc_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext2/feng/feng/workspace/residential_building_challenge/densenet_efficient.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         out = F.avg_pool2d(out, kernel_size=self.avgpool_size).view(\n",
      "\u001b[0;32m~/anaconda3/envs/rbc_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rbc_env/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rbc_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext2/feng/feng/workspace/residential_building_challenge/densenet_efficient.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext2/feng/feng/workspace/residential_building_challenge/densenet_efficient.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mprev_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DenseLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rbc_env/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rbc_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext2/feng/feng/workspace/residential_building_challenge/densenet_efficient.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     57\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_running_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_running_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                                             training=self.training, momentum=0.1, eps=1e-5)\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mrelu_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# The convolutional output - using relu_output which is stored in shared memory allocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext2/feng/feng/workspace/residential_building_challenge/densenet_efficient.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, bn_weight, bn_bias, *inputs)\u001b[0m\n\u001b[1;32m    330\u001b[0m         bn_output_var = F.batch_norm(bn_input_var, self.running_mean, self.running_var,\n\u001b[1;32m    331\u001b[0m                                      \u001b[0mbn_weight_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbn_bias_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                                      momentum=self.momentum, eps=self.eps)\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Do ReLU - and have the output be in the intermediate storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rbc_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected more than 1 value per channel when training, got input size {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "train(model, \n",
    "      train_set, \n",
    "      None, \n",
    "      '/home/feng/ext2/feng/workspace/residential_building_challenge/output', \n",
    "      n_epochs=40, \n",
    "      valid_size=2000,\n",
    "      batch_size=64, \n",
    "      lr=0.1, \n",
    "      wd=0.0001, \n",
    "      momentum=0.9, \n",
    "      seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Visualize training and validation accuracy throughout training history. \n",
    "Visualize loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "valid_loss = []\n",
    "valid_acc = []\n",
    "\n",
    "with open(os.path.join('/home/feng/ext2/feng/workspace/residential_building_challenge/output', 'results.csv'), 'r') as f:\n",
    "        for line in f:\n",
    "            numbers = line.split(',')\n",
    "            if(numbers[0]=='epoch'):\n",
    "                continue\n",
    "            try:\n",
    "                train_loss.append(float(numbers[1]))\n",
    "                train_acc.append(1-float(numbers[2]))\n",
    "                valid_loss.append(float(numbers[3]))\n",
    "                valid_acc.append(1-float(numbers[4]))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "\n",
    "# Visualize loss history and training/validation accuracy history\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_acc, '-o')\n",
    "plt.plot(valid_acc, '-o')\n",
    "plt.legend(['train', 'val'], loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model\n",
    "Make predictions based on test dataset. Visually assess the quality of prediction and compute accuracy based on groundtruth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check accuracy of model on Test set\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=16, shuffle=False,\n",
    "                                              pin_memory=(torch.cuda.is_available()), num_workers=0)\n",
    "test_epoch(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Successful and Failed Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[2,3],[3,4]])\n",
    "mask = [False,False,True]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_success = np.array([]).reshape((0, 1, 200, 200))\n",
    "y_success = np.array([]).reshape((0,))\n",
    "X_failure = np.array([]).reshape((0, 1, 200, 200))\n",
    "y_failure = np.array([]).reshape((0,))\n",
    "\n",
    "model.eval() \n",
    "for X, y in loader_test:\n",
    "    X_var = Variable(X.type(dtype), volatile=True)\n",
    "    scores = model(X_var)\n",
    "    _, preds = scores.data.cpu().max(1)\n",
    "    idx_success = (preds == y).numpy() == 1\n",
    "    idx_failure = (preds != y).numpy() == 1\n",
    "    X = X.numpy()\n",
    "    y = y.numpy()\n",
    "    X_success = np.append(X_success, X[idx_success.tolist(), :, :, :], axis=0)\n",
    "    y_success = np.append(y_success, y[idx_success.tolist(), ], axis=0)\n",
    "    X_failure = np.append(X_failure, X[idx_failure.tolist(), :, :, :], axis=0)\n",
    "    y_failure = np.append(y_failure, preds[idx_failure.tolist(), ], axis=0)\n",
    "    \n",
    "y_success = y_success.astype(np.int32)\n",
    "y_failure = y_failure.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a batch of successfully classified images\n",
    "for i in range(12):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    img = np.moveaxis(X_success[i, :, :, :], 0, -1)\n",
    "    plt.imshow(img[:,:,0])\n",
    "    plt.axis('off')\n",
    "    plt.title(rbc_class_names[y_success[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a batch of incorrectly classified images\n",
    "plt.title('Failure Examples')\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    img = np.moveaxis(X_failure[i, :, :, :], 0, -1)\n",
    "    plt.imshow(img[:,:,0])\n",
    "    plt.axis('off')\n",
    "    plt.title(rbc_class_names[y_failure[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
